{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"InterLab User Guide","text":"<p>InterLab, a research-focused toolkit created to facilitate study and experimentation in the realm of agent interactions, particularly those based on Language Learning Models (LLMs). Our primary objective is to simplify the process of crafting, deploying, and inspecting complex and structured queries within the context of agent interactions, while also providing robust support for interaction logging, UI and visualization. While we maintain a broad scope and plan to include game theoretic agents and a variety of scenarios, our main emphasis lies in the sphere of LLM interactions.</p>"},{"location":"examples/","title":"API Documentation","text":""},{"location":"examples/#notebooks-in-interlab-directory","title":"Notebooks in Interlab directory","text":""},{"location":"examples/#treetrace-examples","title":"TreeTrace examples","text":"<ul> <li>TracingNode intro</li> <li>Visualizations in TracingNode</li> </ul>"},{"location":"examples/#interlab-examples","title":"Interlab examples","text":"<ul> <li>Car negotiation example</li> <li>Example for using web console in Interlab</li> </ul>"},{"location":"installation/","title":"Getting started","text":""},{"location":"installation/#installation-via-poetry-recommended","title":"Installation via Poetry (recommended)","text":"<p>This repository utilizes poetry for package management, which is recommended for dependency installation and is mandatory for InterLab development. Poetry automatically generates and manages a virtual environment for you, and also installs <code>interlab</code> module itself. If you have poetry installed, running the following command will install InterLab:</p> <pre><code>poetry install\n</code></pre>"},{"location":"installation/#installation-via-pip-alternative","title":"Installation via <code>pip</code> (alternative)","text":"<p>Alternatively, <code>pip</code> can be used to install dependencies with <code>pip install -r requirements.txt</code> (core requirements) or <code>pip install -r requirements-full.txt</code> (including development tools, Jupyter Lab, etc.; equivalent to <code>poetry install</code>).</p> <p>Please note, when using <code>pip</code>, you're responsible for managing any virtual environments and deciding where packages should be installed.</p>"},{"location":"installation/#running-jupyter-lab","title":"Running Jupyter Lab","text":"<p>Jupyter Lab provides the simplest way to interact with the code and design experiments:</p> <pre><code>poetry run jupyter lab\n# Or without poetry, in the project root folder:\njupyter lab\n</code></pre> <p>After running the command, open the provided link in your browser. <code>notebooks/car_negotiation.ipynb</code> is a recommended starting point.</p>"},{"location":"installation/#google-colab","title":"Google Colab","text":"<p>Google Colab often offers a lightweight alternative to setting up InterLab locally on your computer. Interlab comes with built-in colab compatibility and we have prepared a example InterLab Colab notebook with common setup and a simple example experiment with two LLMs interacting on behalf of their users.</p>"},{"location":"installation/#note-api-keys","title":"Note: API Keys","text":"<p>In order to use LLM provider serveics and APIs, you need to generate and provide the corresponding API keys. You can provide the keys as environment variables, via <code>.env</code> file, or interactively on every run (e.g. in the colab). Storing keys in the notebook is possible but not recommended (as they easily leak into git or while sharing the code).</p> <p>API keys can be stored in a <code>.env</code> file located in the notebook directory or your home directory. (This file is ignored by <code>git</code> by default, providing an additional security measure.) The file is a simple text file with key=value pairs, for example:</p> <pre><code>OPENAI_API_KEY=sk-...\nOPENAI_API_ORG=org-...\nANTHROPIC_API_KEY=sk-ant-...\n</code></pre> <p>You can then import these variables from the <code>.env</code> file into a Jupyter notebook using the dotenv package.</p> <pre><code>import dotenv\ndotenv.load_dotenv()\n</code></pre>"},{"location":"overview/","title":"Overview","text":"<p>TODO</p>"},{"location":"actors/basics/","title":"Actors","text":"<p>The Actor subsystem within the Interlab library provides a mechanism to create agent-based models with varying levels of complexity. The base class within this subsystem is the BaseActor, which implements the basic interface that all other actors should comply with.</p>"},{"location":"actors/basics/#baseactor-class","title":"BaseActor Class","text":""},{"location":"actors/basics/#baseactor-class_1","title":"BaseActor Class","text":"<p>The <code>BaseActor</code> class serves as an abstract class defining the standard interface for all actors. It contains two essential methods that need to be implemented by any subclass:</p>"},{"location":"actors/basics/#observeself-observation-any","title":"<code>observe(self, observation: Any)</code>","text":"<ul> <li> <p>Description: Processes the given observation. The observation is expected to be a piece of information that the actor perceives from its environment, which should then be integrated into the actor's internal memory or state.</p> </li> <li> <p>Parameters:</p> </li> <li> <p><code>observation</code>: Any digestible information, likely in the form of a string or structured data, that should affect the actor's memory or state.</p> </li> <li> <p>Returns: None.</p> </li> </ul>"},{"location":"actors/basics/#queryself-promptnone-expected_typenone-any","title":"<code>query(self, prompt=None, expected_type=None) -&gt; Any</code>","text":"<ul> <li> <p>Description: Generates a response from the actor based on the provided query and the actor's current memory or state.</p> </li> <li> <p>Parameters:</p> </li> <li> <p><code>prompt</code>: A string that contains the question or request for information to which the actor should respond.</p> </li> <li> <p>Returns: A string or structured data (if expected_type is provided) representing the actor's response.</p> </li> </ul> <p>Note: <code>BaseActor</code> does not prescribe a specific implementation for these methods or the structure of the memory.</p>"},{"location":"actors/basics/#example-usage","title":"Example Usage","text":"<p>The <code>OneShotLLMActor</code> is a concrete implementation provided by Interlab that extends the <code>BaseActor</code>. It utilizes a language model to perform observations and queries in a one-shot manner. This actor stores all observations in its memory and considers them when making a single query through a Language Model.</p> <pre><code>import langchain\nfrom interlab.actor import OneShotLLMActor\n\n# Create a language model instance\nengine = langchain.chat_models.ChatOpenAI(model_name='gpt-3.5-turbo')\n\n# Initialize the OneShotLLMActor with a name, language model, and initial prompt\nactor = OneShotLLMActor(\"Alice\",                                 # Actor's name\n                        engine,                                  # LLM model\n                        \"You are Alice, expert on apples.\")      # Initial prompt\n\n# Feed observations into the actor's memory\nactor.observe(\"Fall is coming.\")\nactor.observe(\"You see an apple tree.\")\n\n# Query the actor to generate a response\nresponse = actor.query(\"What do you do with the tree?\")\n\n# Print out the response from the actor\nprint(response)\n</code></pre> <p>This will perform a one-shot query with the provided language model, including all previous observations within the context.</p>"},{"location":"actors/custom/","title":"<code>BaseActor</code> subclassing","text":"<p>To create a subclass of <code>BaseActor</code>, the following methods should be overridden:</p>"},{"location":"actors/custom/#_observeself-observation-str-any-time-any-none-data-any-none","title":"<code>_observe(self, observation: str | Any, time: Any = None, data: Any = None)</code>","text":"<p>This method handles the observation process. It should take an observation and handle it as necessary for the actor's functionality. <code>time</code> and <code>data</code> may contain optional additional attributes to be stored. Note that some agents may ignore either of these, and not all memory systems support them.</p> <pre><code>from interlab import BaseActor\n\nclass MyActor(BaseActor):\n    def _observe(self, observation):\n        # Process the observation\n        pass\n</code></pre>"},{"location":"actors/custom/#_queryself-prompt-any-none-kwargs-any","title":"<code>_query(self, prompt: Any = None, **kwargs) -&gt; Any</code>","text":"<p>This method processes a query and returns the result. The prompt and any keyword arguments can be used to tailor the query/response logic of the actor.</p> <pre><code>class MyActor(BaseActor):\n    # ... (other methods)\n\n    def _query(self, prompt: Any = None, **kwargs) -&gt; Any:\n        # Process the query and return the result\n        return some_result\n</code></pre>"},{"location":"actors/custom/#copyself","title":"<code>copy(self)</code>","text":"<p>Copy of an actor. By default it makes a deep copy but you can override it.</p>"},{"location":"actors/custom/#actorwithmemory-subclassing","title":"<code>ActorWithMemory</code> Subclassing","text":"<p>When subclassing <code>ActorWithMemory</code>, only the <code>_query</code> method is compulsory to override as it already provides implementations for <code>_observe</code>.</p>"},{"location":"actors/custom/#_queryself-prompt-any-none-kwargs-any_1","title":"<code>_query(self, prompt: Any = None, **kwargs) -&gt; Any</code>","text":"<p>Just like with the <code>BaseActor</code>, you need to implement query processing logic that suits your actor's role.</p> <pre><code>from interlab import ActorWithMemory\n\nclass MyMemoryActor(ActorWithMemory):\n    # ... (other methods, if any)\n\n    def _query(self, prompt: Any = None, **kwargs) -&gt; Any:\n        # Access the memory and process the query\n        return some_result\n</code></pre>"},{"location":"actors/memory/","title":"Memory systems","text":"<p>Most actors need to store their observations and make use of them when queried. InterLab offers a common <code>BaseMemory</code> interface along with several implementations:</p> <ul> <li><code>interlab.actor.memory.ListMemory</code> simply keeps all observations in a list, and    every query has all of them available. Of course, this may run out of LLM context space   in longer scenarios. Also works for non-textual observations (e.g. in GT contexts).</li> <li><code>interlab.actor.memory.experimental.SummarizingMemory</code> summarizes earlier and less terse   textual observations to keep all observations fit a given overall token capacity. Marked   as experimental for now as it has not been thoroughly battle-tested.</li> <li><code>interlab.actor.memory.experimental.SimpleEmbeddingMemory</code> embeds every observation using   an embedding language model. Given a query, it embeds the query and returns up to the   given number or length of relevant memories (ordered temporally). Similarly not as well   tested in our experiments yet.</li> </ul> <p>See the source or the API docs for details of each of the memories.</p>"},{"location":"actors/memory/#memory-and-actors","title":"Memory and actors","text":"<p><code>ActorWithMemory</code> is intended for agents that directly pass their observations to their memory. <code>ActorWithMemory.__init__</code> takes a <code>memory</code> argument, which defauls to a new <code>ListMemory</code>. This is not meant to be a strict hierarchy - you can add memory to any of your own actor implementations, and actors may even perform more than mere recording to memory upon getting an observation.</p>"},{"location":"actors/webactor/","title":"Web Console Actor","text":"<p>The <code>WebConsoleActor</code> facilitates interactive testing of actors, allowing users to dynamically see the observations and manually respond to prompts. This actor serves as an interactive interface without embedded logic; it displays observations to the user in a textual console and, upon receiving a query, prompts the user for input.</p> <p>When a <code>expected_type</code> is specified within a query, the actor presents an automated form, helping to ensure that responses are correctly structured.</p>"},{"location":"actors/webactor/#example","title":"Example","text":"<p>To initialize a web console actor:</p> <pre><code>actor = WebConsoleActor(\"Console actor\")\n</code></pre> <p>In a Jupyter notebook, display the console using:</p> <pre><code>actor.display(height=700)\n</code></pre> <p>Alternatively, access the web console via a browser by navigating to the URL provided by:</p> <pre><code>actor.url\n</code></pre> <p>You can then interact with the actor as demonstrated below:</p> <pre><code>from dataclasses import dataclass\nimport enum\n\nclass DogTitle(enum.Enum):\n    GB = \"Good boy\"\n    GG = \"Good girl\"\n    TBD = \"The Best Dog!\"\n\n@dataclass\nclass Dog:\n    name: str\n    friends: list[str] = field(default_factory=list)\n    age: int | None = None\n    title: DogTitle = DogTitle.TBD\n\na = actor.query('Enter Dog\\'s data. (you can try {\"name\": \"Lassie\", \"age\": 6})', expected_type=Dog)\nprint(f\"Returned: {a!r}\")\n</code></pre> <p>After running query you will get the prompt in web console that allows to create the following dialog on one click:</p> <p></p> <ul> <li>The \"Send Message\" button submits your message directly.</li> <li>The \"Make JSON\" button allows you to preview and verify the final JSON representation of your dialog.</li> </ul>"},{"location":"environments/basics/","title":"Environments","text":"<p>Environments in Interlab are scenarios that consist of communicating actors and follow certain rules or dynamics. An environment can simulate various situations such as pricing negotiations, turn-based games, or any other process that involves a series of interactions.</p>"},{"location":"environments/basics/#the-baseenvironment-class","title":"The BaseEnvironment Class","text":"<p>Every environment in Interlab must inherit from the <code>BaseEnvironment</code> abstract base class, which provides the necessary interface for managing the progression and state of the scenario. The environment can exist in one of two states: \"running\" or \"finished\". The \"running\" state indicates that the environment can proceed to the next state, whereas the \"finished\" state indicates the environment has reached its conclusion.</p> <p>An environment can be set to an finished by calling method <code>.set_finished()</code>. Method <code>.is_finished</code> serves for testing if an environment is in a finished state.</p>"},{"location":"environments/basics/#example-usage-of-environments","title":"Example Usage of Environments","text":"<p>A specific environment called <code>PriceNegotiation</code> is provided by Interlab as a sample implementation of environment. It simulates the scenario of two parties negotiating a price. Here's an example of how to use it:</p> <pre><code>from interlab import actor\nfrom interlba.environment.experimantal.negotiation import PriceNegotiation\nfrom treetrace import TracingNode\nimport langchain\n\n# Initialize the language model for the actors.\ne35 = langchain.chat_models.ChatOpenAI(model_name='gpt-3.5-turbo')\n\n# Create actors with their initial statements.\npa = actor.OneShotLLMActor(\"Alice\", e35, \"I want to buy ...\")\npb = actor.OneShotLLMActor(\"Bob\", e35, \"I want to sell ...\")\n\n# Setup the PriceNegotiation environment.\nenv = PriceNegotiation(minimizer=pa, maximizer=pb, max_steps=10)\n\n# Run the simulation inside a tracing node, storing the result.\nwith TracingNode(\"negotiation\", storage=storage) as ctx:\n    while not env.is_finished:\n        env.step()\n</code></pre>"},{"location":"environments/basics/#methods-and-attributes-of-baseenvironment","title":"Methods and attributes of BaseEnvironment","text":"<p><code>BaseEnvironment</code> provides the folowing methods:</p> <ul> <li><code>.step()</code> - Proceeds a single step in the environment. Raises an exception if the environment has already finished. Each call to <code>.step()</code> creates a new context for that step.</li> <li><code>.copy()</code> - Creates a stand-alone copy of the environment.</li> <li><code>.set_finished()</code> - Puts the environment in finished state.</li> </ul> <p><code>BaseEnvironment</code> provides the folowing attributes:</p> <ul> <li><code>.is_finished -&gt; boolean</code> - Checks if the environment is in a terminal state and returns True if it is.</li> <li><code>.steps -&gt; int</code> - The current number of step counter</li> </ul>"},{"location":"environments/custom/","title":"Subclassing","text":""},{"location":"environments/custom/#subclassing-baseenvironment","title":"Subclassing BaseEnvironment","text":"<p>To create custom environments, you shold inherit from <code>BaseEnvironment</code> and implement the <code>_step_()</code>:</p> <pre><code>class MyEnv(BaseEnvironment):\n    def _step(self):\n        # Implement the logic for a single step.\n</code></pre> <p>If a deep copy is not optimal for you, you may also write your own implementation of <code>copy()</code> method.</p>"},{"location":"tracing/basics/","title":"Tracing","text":"<p>Independendent part of Interlab project is TreeTrace module. TreeTrace is framework for logging, tracing, storing results and and visualisation of nested computations and actor interactions. They are designed to support large textual and structured (e.g. JSON) inputs and outputs, as well as generic and custom visualisations. custom visualisations.</p> <p>An instance of TracingNode is a core object of InterLab logging infrastructure and represents a single (sub)task in a nested hierarchy.</p>"},{"location":"tracing/basics/#using-a-tracingnode-as-a-context-manager","title":"Using a TracingNode as a context manager","text":"<p>To utilize a TracingNode within your code, here's a pattern involving <code>with</code> statements:</p> <pre><code>from treetrace import TracingNode\n\nwith TracingNode(\"my node\", inputs={\"x\": 42}) as c:\n    y = do_a_computation(x=42)\n    c.set_result(y)\n</code></pre>"},{"location":"tracing/basics/#hierarchically-nested-tracing-nodes","title":"Hierarchically nested tracing nodes","text":"<p>TracingNodes can be nested to construct a clear hierarchy reflecting the structure of a complex computation:</p> <pre><code>with TracingNode(\"root\") as root:\n    with TracingNode(\"child-1\"):\n       with TracingNode(\"child-1-1\"):\n           pass\n       with TracingNode(\"child-1-2\"):\n           pass\n    with TracingNode(\"child-2\"):\n       pass\n</code></pre> <p>If this tracing nodes are visualized in Data Browser or in Jupyter notebook via <code>root.display()</code>:</p> <p></p>"},{"location":"tracing/basics/#tracingnode-states","title":"TracingNode states","text":"<p>Throughout its lifetime, a TracingNode traverses several states:</p> <ul> <li>New -  Freshly instantiated TracingNode</li> <li>Open - Running TracingNode</li> <li>Finished - Successfully finished TracingNode</li> <li>Error - Unsuccessfully finished TracingNode</li> </ul> <pre><code>node = TracingNode(\"my node\")  # 'node' in NEW state\nwith node:\n    # 'node' in OPEN state\n    compute_something()\n# 'node' in FINISHED state\n</code></pre> <p>When an unhandled exception passes through a ContentNode boundary, it sets the node to the ERROR state. Example:</p> <pre><code>with TracingNode(\"my node\"):\n    raise Exception(\"Something is wrong\")\n# TracingNode in ERROR state\n</code></pre> <p>Alternatively, the <code>.set_error(error)</code> method can be called on a node to explicitly set the node to the ERROR state.</p>"},{"location":"tracing/basics/#managing-inputs-and-results","title":"Managing Inputs and Results","text":"<p>Nodes may have one or more named inputs and at most one result</p> <pre><code>from treetracing import TracingNode\n\nwith TracingNode(\"my node\", inputs={\"x\": 42}) as node:  # Set inputs when tracing is created\n    node.add_inputs({\"y\": 123, \"z\": 321})  # Add inputs dynamically\n    node.set_result(\"my_result\")  # Set result explicitly\n</code></pre> <p>The name of the input has to be string.</p>"},{"location":"tracing/basics/#enhancing-functions-with-with_tracing","title":"Enhancing Functions with <code>with_tracing</code>","text":"<p>A function can be annotated with with_tracing decorator. It automatically creates a new <code>TracingNode</code> that captures inputs and the result when the function is called.</p> <pre><code>from treetrace import with_trace\n\n\n@with_trace\ndef my_computation(x):\n    ...\n</code></pre>"},{"location":"tracing/basics/#events","title":"Events","text":"<p>An event is an instant TracingNode with immediate result and no child nodes.</p> <pre><code>with TracingNode(\"root\") as node:\n    node.add_event(\"Message to Alice\", kind=\"message\", data=\"Hi, Alice!\")\n</code></pre>"},{"location":"tracing/basics/#tags","title":"Tags","text":"<p>Utilizing Tags</p> <p>Tags are custom identifiers attachable to any TracingNode, facilitating subsequent filtering based on these tags. A tag is either directly a string or an instance of <code>Tag</code>.</p> <p>Tag appearances in the Data Browser can be customized with an associated HTML color:</p> <pre><code>from treetrace import TracingNode, Tag\n\nwith TracingNode(\"root\", tags=[\"tag1\", Tag(\"tag2\")]) as node:\n    node.add_tag(\"exp1\")  # Add tag to a tracing node dynamically\n    node.add_tag(Tag(\"success!\", color=\"lightgreen\"))  # Add a tag with custom color\n</code></pre>"},{"location":"tracing/basics/#attaching-meta-information","title":"Attaching Meta information","text":"<p>A meta information can be attached to any <code>TracingNode</code>. It is a dictionary with string keys. Keys and values may be user defined; however, some keys are recognized by DataBrowser and influences how the tracing node is rendered.</p> <pre><code>with TracingNode(\"root\", meta={\"key\": \"value\"}) as node:\n    pass\n</code></pre> <p>InterLab specifically recognizes and utilizes the following metadata keys, influencing the visual rendering in the Data Browser:</p> <ul> <li>\"color\": [HTML color] - Defines the main color of the tracing node. In the current version, it is used for the title of node and a line when the node is expanded.</li> <li>\"color_bg\": [HTML color] - Sets the TracingNode's background color.</li> <li>\"color_border\": [HTML color] - Draws a border with the specified color around the TracingNode.</li> </ul>"},{"location":"tracing/databrowser/","title":"Data Browser","text":""},{"location":"tracing/databrowser/#static-and-dynamic-visualtion-of-tracing-nodes","title":"Static and dynamic visualtion of tracing nodes","text":"<p>There two main ways how visualize a <code>TracingNode</code>:</p> <ul> <li>Static - creates a standalone HTML code that captures a snaphost of the current state of the tracing node.   Visulation is not updated when the nodes evolves.</li> <li>Dynamic (live) - it dynamically reflects the current state of the node. It needs a running storage server (Storage);</li> </ul>"},{"location":"tracing/databrowser/#static-view","title":"Static view","text":"<p>To create a static view you can call <code>.create_html(path)</code> that create a HTML file that contains a visualization of the node.</p> <p>In Jypter notebook you can directly call <code>.display()</code> on a node to create a static view of the node that is immediately shown in Jupyter.</p>"},{"location":"tracing/databrowser/#live-data-browser-as-a-stand-alone-page","title":"Live Data Browser as a stand-alone page","text":"<p>Live data browser works only when node is stored in a storage.</p> <p>Method <code>.start_server()</code> returns a handle where a HTTP server is running.</p> <pre><code>from treetrace import TracingNode, FileStorage\n\nstorage = FileStorage(\"./my-directory\")\nstorage.start_server()  # returns &lt;ServerHandle http://localhost:PORT&gt;\n</code></pre> <p>The Data browser is running on the given address. If you register the root node in the storage, e.g.:</p> <pre><code>with TracingNode(\"my test\", storage=storage):\n    with TracingNode(\"a child\"):\n        pass\n    with TracingNode(\"a child\"):\n        pass\n</code></pre> <p>and refreshes the view then a new node occurs. The icon for refreshing Data Browser is shown in the following figure:</p> <p></p>"},{"location":"tracing/databrowser/#live-data-browser-in-jupyter","title":"Live Data Browser in Jupyter","text":"<p>In Jupyter notebook, a storage have a method <code>.live_display</code> that internally starts the server shows a Data Browser directly in Jupyter notebook.</p> <pre><code>storage = FileStorage(\"./my-directory\")\nstorage.live_display() # Shows Data browser in the resulting Jupyter output cell\n</code></pre>"},{"location":"tracing/databrowser/#embedded-html","title":"Embedded HTML","text":"<p>TODO</p>"},{"location":"tracing/databrowser/#data-with-mime-type","title":"Data with MIME type","text":"<p>TODO</p>"},{"location":"tracing/serialization/","title":"Serialization to JSON","text":"<p><code>TracingNode</code> can be serialized into JSON via to_dict method:</p> <pre><code>from treetrace import TracingNode\n\nwith TracingNode(\"my node\", inputs={\"x\": 42}) as node:\n    node.set_result(\"my_result\")\n</code></pre> <p>Calling <code>node.to_dict()</code> returns:</p> <pre><code>{\n  \"_type\": \"TracingNode\",\n  \"name\": \"my node\",\n  \"uid\": \"2023-08-23T16-41-35-my_node-Z9YpEb\",\n  \"inputs\": {\n    \"x\": 42\n  },\n  \"result\": \"my_result\",\n  \"start_time\": \"2023-08-23T16:41:35.811159\",\n  \"end_time\": \"2023-08-23T16:41:35.811210\"\n}\n</code></pre> <p>When inputs or a result are not directly serializable into JSON options are provided:</p>"},{"location":"tracing/serialization/#serialization-of-dataclasses","title":"Serialization of dataclasses","text":"<p>Dataclasses are serialized as <code>dict</code>:</p> <pre><code>from dataclasses import dataclass\nfrom treetrace import TraceNode, with_trace\n\n@dataclass\nclass Person:\n    name: str\n    age: int\n\n@with_trace\ndef say_hi(person):\n    return f\"Hi {person.name}!\"\n\nwith TracingNode(\"root\") as c:\n    person = Person(\"Alice\", 21)\n    say_hi(person)\n</code></pre> <p>creates the following JSON description of the node:</p> <pre><code>{\n  \"_type\": \"TracingNode\",\n  \"name\": \"root\",\n  \"uid\": \"2023-08-23T16:52:43-root-H4JCSN\",\n  \"children\": [\n    {\n      \"_type\": \"TracingNode\",\n      \"name\": \"say_hi\",\n      \"uid\": \"2023-08-23T16:52:43-say_hi-GGfCCe\",\n      \"kind\": \"call\",\n      \"result\": \"Hi Alice!\",\n      \"inputs\": {\n        \"person\": {                     # &lt;&lt;&lt;&lt;\n          \"name\": \"Alice\",              # &lt;&lt;&lt;&lt;\n          \"age\": 21,                    # &lt;&lt;&lt;&lt;\n          \"_type\": \"Person\"             # &lt;&lt;&lt;&lt;\n        }\n      },\n      \"start_time\": \"2023-08-23T16:52:43.115548\",\n      \"end_time\": \"2023-08-23T16:52:43.115572\"\n    }\n  ],\n  \"start_time\": \"2023-08-23T16:52:43.115449\",\n  \"end_time\": \"2023-08-23T16:52:43.115585\"\n}\n</code></pre>"},{"location":"tracing/serialization/#method-__trace_to_node__","title":"Method <code>__trace_to_node__</code>","text":"<p>A user type may define method <code>__trace_to_node__</code> to provide a custom serializer.</p> <pre><code>class Person:\n    name: str\n    age: int\n\n    def __init__(self, name, age):\n        self.name = name\n        self.age = age\n\n    def __trace_to_node__(self):\n        return {\"name\": self.name, \"age\": self.age}\n\nperson = Person(\"Peter\", 24)\n</code></pre> <p>When <code>person</code> is serialized, the following dictionary is produced:</p> <pre><code>{\n    \"name\": \"Peter\",\n    \"age\": 24,\n    \"_type\": \"Person\"\n}\n</code></pre>"},{"location":"tracing/serialization/#registration-of-serializer","title":"Registration of serializer","text":"<p>Sometimes we do not or we cannot modify a class. Registration a serializer for a given type is there for this purpose.</p> <pre><code>from treetrace import register_custom_serializer\n\n\nclass MyClass:\n    def __init__(self, x):\n        self.x = x\n\n\ndef myclass_serializer(m: MyClass):\n    return {\"x\": m.x}\n\n\nregister_custom_serializer(MyClass, myclass_serializer)\n</code></pre>"},{"location":"tracing/serialization/#fallback","title":"Fallback","text":"<p>When no mechanism above is used then only name of the type and object <code>id</code> is serialized.</p> <p>E.g.:</p> <pre><code>{\n    \"_type\": \"Person\",\n    \"id\": 140263930622832\n}\n</code></pre>"},{"location":"tracing/storage/","title":"Storage","text":"<p>InterLab storage manages serialized tracing nodes. The current implementation allows to store nodes as (compresed) files into a directory structure.</p>"},{"location":"tracing/storage/#basics","title":"Basics","text":"<p>Storage can be initialized by instantiating FileStorage</p> <pre><code>from treetrace import FileStorage\n\nstorage = FileStorage(\"/path/to/a/directory\")\n</code></pre> <p>A node can be written manually as follows:</p> <pre><code>with TracingNode(\"root\") as ctx:\n    pass\n\nstorage.write_node(ctx)\n</code></pre> <p>Or a node can be directly created with storage:</p> <pre><code>with TracingNode(\"root\", storage=storage):\n    pass\n</code></pre> <p>The latter have advantage that the node is known to the storage from the initialization and it is visible in Data Browser even in the running state. However, node is physically written into the persistent storage after the computation is finished.</p>"},{"location":"tracing/storage/#storage-and-with-block","title":"Storage and <code>with</code> block","text":"<p>Storage can be used as a context manager, in such a case all root nodes are automatically written into the storage.</p> <pre><code>from treetrace import FileStorage, TracingNode\n\nstorage = FileStorage(\"/path/to/a/directory\")\nwith storage:\n    with TracingNode(\"my root\"):\n        pass\n</code></pre>"},{"location":"tracing/storage/#directory","title":"Directory","text":"<p>By default a node is stored into a single file with all its children. If <code>directory</code> flag is set to <code>True</code> then the node is stored as a directory and its children are stored in files in it (or sub-directories when a child has also <code>directory</code> flag).</p> <pre><code>with TracingNode(\"root\", directory=True, storage=storage):  # &lt;-- Stored as a dictionary\n    with TracingNode(\"child1\"):  # &lt;-- Stored as file\n        pass\n</code></pre>"},{"location":"tracing/storage/#loading-tracing-nodes","title":"Loading tracing nodes","text":"<p>Tracing nodes can be loaded from storage.</p> <pre><code># Read all stored (root) nodes\nfor node in storage.read_all_nodes():\n    ...\n\n# Recursively search for specific tracing nodes\nfor node in storage.find_nodes(lambda ctx: ctx.has_tag_name(\"hello\")):\n    ...\n\n# Read a tracing node by uid\nnode = storage.read_node(uid)\n</code></pre>"}]}